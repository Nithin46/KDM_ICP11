# -*- coding: utf-8 -*-
"""KDM_ICP11.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fWEr8hg_sgI_H5Fd5JpcI_PV7Lf78q1i

Importing all the necessary packages and Dataset. 

I have downloaded the CIFAR-10 (Canadian Institute For Advanced Research) Dataset for this assignment. The dataset consists of 60,000 32 x 32 colour images in 10 classes, with 6,000 images per class. There are 50,000 training images and 10,000 test images.

These images are taken in varying lighting conditions and at different angles, and since these are colored images, and we will see that there are many variations in the color itself of similar objects.

Key things are:

*   Images are colored in CIFAR-10
*   Each image is 32 x 32 pixel
"""

import numpy as np
import tensorflow as tf
from keras.datasets import cifar10
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout
from keras.utils import to_categorical
from keras.utils import np_utils



(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()

# Normalize the images.
train_images = (train_images / 255) - 0.5
test_images = (test_images / 255) - 0.5

# Reshape the images.

train_images = train_images.reshape(train_images.shape[0], 32, 32, 3)
test_images = test_images.reshape(test_images.shape[0], 32, 32, 3)
train_images = train_images.astype('float32')
test_images = test_images.astype('float32')

print(train_images.shape)
test_images.shape

test_label = test_labels
train_labels = np_utils.to_categorical(train_labels)
test_labels = np_utils.to_categorical(test_labels)

print(train_labels.shape)
print(test_labels.shape)

num_filters = 10
filter_size = 3
pool_size = 2

# Build the model.
model = Sequential([
  Conv2D(num_filters, filter_size, input_shape=(32, 32, 3)),
  MaxPooling2D(pool_size=pool_size),
  Dropout(0.5),
  Flatten(),
  Dense(10, activation='softmax'),
])

# Compile the model.
model.compile(
  optimizer ='adam',
  loss='categorical_crossentropy',
  metrics=['accuracy'],
)

# Train the model.
model.fit(
  train_images,
  train_labels,
  epochs=15,
  validation_data=(test_images,test_labels)
)

# Predict on the first 5 test images.
predictions = model.predict(test_images[:10])

# Print our model's predictions.
print("These are the model predictions :")
print(np.argmax(predictions, axis=1))
print("\n")

# Check our predictions against the ground truths.
print("These are the corresponding labels :")
print(test_label[:10])